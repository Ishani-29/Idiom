{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3690d6-40bb-4c71-b772-dfcf39f70b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login('hugging_face_token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "277713e8-3b9f-46d4-9b53-a24613309777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeef490b-c5a2-4b0f-a539-df517ca431bc",
   "metadata": {},
   "source": [
    "# Load Model and Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31fc73d6-ae80-4922-8008-26b706837f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 18:06:15.593932: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738753575.619119  282656 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738753575.626609  282656 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-05 18:06:15.650540: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(128128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(128128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(128128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=128128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"rahular/varta-t5\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"rahular/varta-t5\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07994b0-90b2-48f0-98e0-f722525cb266",
   "metadata": {},
   "source": [
    "# Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc02c7ee-6cc3-4800-a843-b034e585f1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Proverb</th>\n",
       "      <th>Final_Human_Annotation</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>अधजल गगरी छलकत जाय।</td>\n",
       "      <td>The Hindi proverb \"अधजल गगरी छलकत जाय\" transla...</td>\n",
       "      <td>hindi_img/0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>अपने मुँह मियाँ मिट्ठू बनाना।</td>\n",
       "      <td>The Hindi proverb \"अपने मुँह मियाँ मिट्ठू बना...</td>\n",
       "      <td>hindi_img/1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>अपने हाथ में अपना भाग्य होना।</td>\n",
       "      <td>To create a clear and highly specific visualiz...</td>\n",
       "      <td>hindi_img/2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>अपना उल्लू सीधा करना।</td>\n",
       "      <td>The Hindi proverb \"अपना उल्लू सीधा करना\" trans...</td>\n",
       "      <td>hindi_img/3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>अँगारे बरसना</td>\n",
       "      <td>Certainly! Here is a revised version with a cl...</td>\n",
       "      <td>hindi_img/4.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Actual Proverb  \\\n",
       "0            अधजल गगरी छलकत जाय।   \n",
       "1  अपने मुँह मियाँ मिट्ठू बनाना।   \n",
       "2  अपने हाथ में अपना भाग्य होना।   \n",
       "3          अपना उल्लू सीधा करना।   \n",
       "4                   अँगारे बरसना   \n",
       "\n",
       "                              Final_Human_Annotation         img_path  \n",
       "0  The Hindi proverb \"अधजल गगरी छलकत जाय\" transla...  hindi_img/0.png  \n",
       "1   The Hindi proverb \"अपने मुँह मियाँ मिट्ठू बना...  hindi_img/1.png  \n",
       "2  To create a clear and highly specific visualiz...  hindi_img/2.png  \n",
       "3  The Hindi proverb \"अपना उल्लू सीधा करना\" trans...  hindi_img/3.png  \n",
       "4  Certainly! Here is a revised version with a cl...  hindi_img/4.png  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "\n",
    "df = pd.read_csv('training_df.csv')\n",
    "df = df.drop('Descriptive Meaning by ChatGPT', axis=1)\n",
    "df['img_path'] = ''\n",
    "for i in range(len(df)):\n",
    "    df.loc[i,'img_path'] = 'hindi_img/'+str(i)+'.png'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dcb2d8d-ad9a-49ae-82fe-91656def9f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((816, 3), (205, 3), (256, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(temp_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49cd77a-6917-43c9-a4f8-4fe7cf1dc466",
   "metadata": {},
   "source": [
    "## Try Tokenizer & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27dcadd9-e3db-445d-9441-3b0724c592dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: What is meaning of proverb named रेल-पेल होना ?\n",
      "\n",
      "Label: Certainly! Here's a more specific description for the visual representation:\n",
      "\n",
      "Imagine a bustling train station platform during peak hours. The scene is packed with a dense crowd of people, each person tightly packed against the others. Individuals are jostling to get closer to the edge of the platform, where an incoming train is arriving. A variety of people are shown: a woman clutching her bag tightly, a man looking at his watch anxiously, a group of school children trying to navigate through the throng, and a vendor holding a tray of snacks high above his shoulder to avoid the crush. The expressions on their faces range from impatience to frustration, capturing the chaos and urgency of the moment. In the background, the blurred motion of the approaching train adds to the sense of hustle and frenzy.\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"What is meaning of proverb named \" + train_df.loc[0,'Actual Proverb'] + \" ?\", return_tensors=\"pt\")\n",
    "labels = tokenizer(train_df.loc[0, \"Final_Human_Annotation\"], return_tensors=\"pt\").input_ids\n",
    "\n",
    "print(\"Input:\", \"What is meaning of proverb named \" + train_df.loc[0,'Actual Proverb'] + \" ?\\n\")\n",
    "print(\"Label:\", train_df.loc[0, \"Final_Human_Annotation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5fea58b-7406-4f5a-8439-bef3ed3ce555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is meaning of proverb named रेल-पेल होना ?</s>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6714527b-ac75-4fb3-8f71-28abc4909a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Certainly! Here's a more specific description for the visual representation: Imagine a bustling train station platform during peak hours. The scene is packed with a dense crowd of people, each person tightly packed against the others. Individuals are jostling to get closer to the edge of the platform, where an incoming train is arriving. A variety of people are shown: a woman clutching her bag tightly, a man looking at his watch anxiously, a group of school children trying to navigate through the throng, and a vendor holding a tray of snacks high above his shoulder to avoid the crush. The expressions on their faces range from impatience to frustration, capturing the chaos and urgency of the moment. In the background, the blurred motion of the approaching train adds to the sense of hustle and frenzy.</s>\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ed0673-1184-4a89-8369-2b1c0c70bda6",
   "metadata": {},
   "source": [
    "## custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdd81edb-94f1-446b-bc93-3a86bacfe896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "class HindiDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = {\n",
    "            \"texts_input\": self.df.loc[idx, 'Actual Proverb'],\n",
    "            'texts_label': self.df.loc[idx, 'Final_Human_Annotation']\n",
    "        }\n",
    "        return row\n",
    "\n",
    "def collate_fn(batch, tokenizer, device):\n",
    "    input_lis = [r['texts_input'] for r in batch]\n",
    "    label_lis = [r['texts_label'] for r in batch]\n",
    "    inputs = tokenizer(\n",
    "        text=input_lis, return_tensors=\"pt\", padding=\"max_length\", max_length=512, truncation=True\n",
    "    )\n",
    "    inputs.pop('token_type_ids', None)\n",
    "    inputs = {key: valu.to(device) for key, valu in inputs.items()}\n",
    "    labels_ids = tokenizer(\n",
    "        text=label_lis, return_tensors=\"pt\", padding=\"max_length\", max_length=512, truncation=True\n",
    "    ).input_ids\n",
    "    labels_ids = labels_ids.to(device)\n",
    "    return inputs, labels_ids\n",
    "    \n",
    "train_dataset = HindiDataset(train_df)\n",
    "val_dataset = HindiDataset(val_df)\n",
    "test_dataset = HindiDataset(test_df)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=8,\n",
    "        collate_fn=partial(collate_fn, tokenizer=tokenizer, device=device)\n",
    "    )\n",
    "val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=4,\n",
    "        collate_fn=partial(collate_fn, tokenizer=tokenizer, device=device)\n",
    "    )\n",
    "test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=4,\n",
    "        collate_fn=partial(collate_fn, tokenizer=tokenizer, device=device)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adeb366-6199-4299-a108-99a4c7bbed05",
   "metadata": {},
   "source": [
    "# Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "621e4592-bfcd-47ce-ab44-30c88377fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "epochs = 15\n",
    "train_steps = len(train_loader) * epochs\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=int(0.1 * train_steps), num_training_steps=train_steps\n",
    ")\n",
    "loss_fct = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2209345-f7cc-47e4-a5a9-3244c58f0bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69778fccc14f4800950fcdfebea63fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Epoch 1 - Training Loss: 8.9240\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3186792ee40d4eafa5e875e7da902dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "🔍 Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 1 - Validation Loss: 6.8760\n",
      "💾 Best model saved at Epoch 1\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb019031f2a4f3fa88b926526995504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 2:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Epoch 2 - Training Loss: 6.8700\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8877a531e54e48fb917697c0d92d909f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "🔍 Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 2 - Validation Loss: 5.9959\n",
      "💾 Best model saved at Epoch 2\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253338a4f78742a2b09ca72939208fd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 3:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Epoch 3 - Training Loss: 6.2348\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2fa51640ad04bfc9bbe9c03c123b1b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "🔍 Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 3 - Validation Loss: 5.5270\n",
      "💾 Best model saved at Epoch 3\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda4848815f84ca5af2812fd33f9423e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 4:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Epoch 4 - Training Loss: 5.8324\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde541aad09c4c68a6dcc50b400eee6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "🔍 Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 4 - Validation Loss: 5.2449\n",
      "💾 Best model saved at Epoch 4\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d930150aea76407fa881cd21cbb68e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 5:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Epoch 5 - Training Loss: 5.5762\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a275b1b40e48d4920ac59ea8f74a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "🔍 Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 5 - Validation Loss: 5.0645\n",
      "💾 Best model saved at Epoch 5\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356222d871a9447eb3a8df7426ed4344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 6:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Epoch 6 - Training Loss: 5.3949\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79afa56bd7344479b995bf87ffd1ca35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "🔍 Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 6 - Validation Loss: 4.9346\n",
      "💾 Best model saved at Epoch 6\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6481f7518841e0bb24d22186a8d62f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 7:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Epoch 7 - Training Loss: 5.2579\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba80560e138540fbaff0920dd3f8753c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "🔍 Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 7 - Validation Loss: 4.8349\n",
      "💾 Best model saved at Epoch 7\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6939dbf67b477086eb9e3da3986727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 8:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Epoch 8 - Training Loss: 5.1578\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5acc418de78d43f6aa43a97ee6889468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "🔍 Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 8 - Validation Loss: 4.7626\n",
      "💾 Best model saved at Epoch 8\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a047a91d4345e7b48b3d3cc6c5e71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 9:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Epoch 9 - Training Loss: 5.0878\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a741549cc89a468daf1c5e54412b0172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "🔍 Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 9 - Validation Loss: 4.7081\n",
      "💾 Best model saved at Epoch 9\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b474d187c4f54b25a73719c891aaf6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 10:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Epoch 10 - Training Loss: 5.0263\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9137be4d6f184aaabcc38234a2c2c246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "🔍 Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 10 - Validation Loss: 4.6665\n",
      "💾 Best model saved at Epoch 10\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec6ae2a694049a298adc5c0e20043d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 11:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Epoch 11 - Training Loss: 4.9886\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3640eca64b746a8a2109f6a920d3a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "🔍 Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 11 - Validation Loss: 4.6389\n",
      "💾 Best model saved at Epoch 11\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f083841c06494487b08e382da7956d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 12:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Epoch 12 - Training Loss: 4.9562\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6653a115de31448d927e587c7058bd76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "🔍 Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 12 - Validation Loss: 4.6219\n",
      "💾 Best model saved at Epoch 12\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499354a0da774d4582d816bf8b7aa3ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 13:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Epoch 13 - Training Loss: 4.9401\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3056d18b77614f4d86bd4dae733ef81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "🔍 Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 13 - Validation Loss: 4.6131\n",
      "💾 Best model saved at Epoch 13\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5757399c03c04d999453f8281a943e3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 14:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Epoch 14 - Training Loss: 4.9294\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d435d7f4bf742a28fbe0ea8dd047c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "🔍 Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 14 - Validation Loss: 4.6099\n",
      "💾 Best model saved at Epoch 14\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01212e1d36634ff28661e9b50824f70f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 15:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Epoch 15 - Training Loss: 4.9302\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add79cb63d1240d49605708f921bf055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "🔍 Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 15 - Validation Loss: 4.6094\n",
      "💾 Best model saved at Epoch 15\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_progress = tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}\", leave=True, position=0)\n",
    "    for input_ids, labels in train_progress:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(\n",
    "            input_ids=input_ids['input_ids'],\n",
    "            attention_mask=input_ids['attention_mask'],\n",
    "            labels=labels\n",
    "        )\n",
    "        logits = outputs.logits  \n",
    "        shift_logits = logits[:, :-1, :].contiguous().view(-1, logits.size(-1))\n",
    "        shift_labels = labels[:, 1:].contiguous().view(-1)\n",
    "        loss = loss_fct(shift_logits, shift_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        running_loss += loss.item()\n",
    "        train_progress.set_postfix(loss=loss.item())\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    tqdm.write(f\"\\n🎯 Epoch {epoch + 1} - Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_progress = tqdm(val_loader, desc=\"🔍 Validation\", leave=True, position=0)\n",
    "    with torch.no_grad():\n",
    "        for input_ids, labels in val_progress:\n",
    "            outputs = model(\n",
    "                input_ids=input_ids['input_ids'],\n",
    "                attention_mask=input_ids['attention_mask'],\n",
    "                labels=labels\n",
    "            )\n",
    "            logits = outputs.logits  \n",
    "            shift_logits = logits[:, :-1, :].contiguous().view(-1, logits.size(-1))\n",
    "            shift_labels = labels[:, 1:].contiguous().view(-1)\n",
    "            loss = loss_fct(shift_logits, shift_labels)\n",
    "            val_loss += loss.item()\n",
    "            val_progress.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    tqdm.write(f\"✅ Epoch {epoch + 1} - Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        os.makedirs(\"art_t5/\", exist_ok=True)\n",
    "        model.save_pretrained(\"art_t5/best_model\", from_pt=True)\n",
    "        tqdm.write(f\"💾 Best model saved at Epoch {epoch + 1}\")\n",
    "    tqdm.write(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8281d63c-3ffb-4500-a58f-20a89eecd7c0",
   "metadata": {},
   "source": [
    "# load best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3be3691e-e7ad-425d-b99a-1744781ca3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "\n",
    "# best_model = T5ForConditionalGeneration.from_pretrained(\"./art_t5/best_model/\")\n",
    "# best_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12827e6-0ffe-4cd3-90d4-6b410199abf6",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "477e96cf-3c69-49da-b3df-43ceb3087937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e2879196704f978f6cccfa4249fcd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "op_lis, lb_lis = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, l in tqdm(test_loader, desc=\"test\"):\n",
    "        generated_ids = model.generate(i[\"input_ids\"])\n",
    "        output_text = tokenizer.batch_decode(\n",
    "            generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "        )\n",
    "        label_text = tokenizer.batch_decode(\n",
    "            l, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "        )\n",
    "        op_lis.extend(output_text)\n",
    "        lb_lis.extend(label_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff2ed3c1-7275-4876-8c75-ff348787488e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hindirbठना translate tototo a orto a orto a or...</td>\n",
       "      <td>The Hindi proverb 'ठंडी आहें भरना' translates ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hindirb पत्थर लकीर (stonestick)shor)shorsshorss</td>\n",
       "      <td>The Hindi proverb 'पत्थर की लकीर' translates t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hindirb मक्खन लगाना translate totoing oring so...</td>\n",
       "      <td>The Hindi proverb 'मक्खन लगाना' translates to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hindirbचमना translate tototo a of a or a, a or...</td>\n",
       "      <td>To visually represent this proverb, consider a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hindirbएकनाँना translate tototo a orto in.toto...</td>\n",
       "      <td>The Hindi proverb 'अकेला हँसता भला न रोता भला।...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Hindirbसाप दूधना translate tototo milk in. des...</td>\n",
       "      <td>The proverb 'साँप को दूध पिलाना' translates to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Hindirbसजबाग दिखा'sssssssssssss</td>\n",
       "      <td>Certainly! I'll refine the visualization to ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>Hindirbताव आना translate totototototototototot...</td>\n",
       "      <td>The Hindi proverb 'ताव आना' translates to \"to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>Hindirbधना translate tototo a orto in. describ...</td>\n",
       "      <td>The Hindi proverb 'दृष्टि फिरना' translates to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>Hindirbढ पड़ना translate tototo a orto in. des...</td>\n",
       "      <td>The Hindi proverb 'बरस पड़ना' translates to 't...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                output  \\\n",
       "0    Hindirbठना translate tototo a orto a orto a or...   \n",
       "1      Hindirb पत्थर लकीर (stonestick)shor)shorsshorss   \n",
       "2    Hindirb मक्खन लगाना translate totoing oring so...   \n",
       "3    Hindirbचमना translate tototo a of a or a, a or...   \n",
       "4    Hindirbएकनाँना translate tototo a orto in.toto...   \n",
       "..                                                 ...   \n",
       "251  Hindirbसाप दूधना translate tototo milk in. des...   \n",
       "252                    Hindirbसजबाग दिखा'sssssssssssss   \n",
       "253  Hindirbताव आना translate totototototototototot...   \n",
       "254  Hindirbधना translate tototo a orto in. describ...   \n",
       "255  Hindirbढ पड़ना translate tototo a orto in. des...   \n",
       "\n",
       "                                                 label  \n",
       "0    The Hindi proverb 'ठंडी आहें भरना' translates ...  \n",
       "1    The Hindi proverb 'पत्थर की लकीर' translates t...  \n",
       "2    The Hindi proverb 'मक्खन लगाना' translates to ...  \n",
       "3    To visually represent this proverb, consider a...  \n",
       "4    The Hindi proverb 'अकेला हँसता भला न रोता भला।...  \n",
       "..                                                 ...  \n",
       "251  The proverb 'साँप को दूध पिलाना' translates to...  \n",
       "252  Certainly! I'll refine the visualization to ma...  \n",
       "253  The Hindi proverb 'ताव आना' translates to \"to ...  \n",
       "254  The Hindi proverb 'दृष्टि फिरना' translates to...  \n",
       "255  The Hindi proverb 'बरस पड़ना' translates to 't...  \n",
       "\n",
       "[256 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df = pd.DataFrame({'output': op_lis, 'label': lb_lis})\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d38127b-d36a-4bb7-9e10-254c54d16e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hindirbठना translate tototo a orto a orto a orto a orto'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['output'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0754bb4-a4f7-4647-aea6-860008022269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Hindi proverb 'ठंडी आहें भरना' translates to 'sighing deeply' in English. It signifies a state of deep sorrow, regret, or longing. The imagery associated with this proverb can be visualized with an individual sitting on a wooden bench in a dimly lit park, under the soft glow of a solitary streetlamp. The person, wearing a dark, weathered coat, is exhaling slowly with a melancholic expression. One hand rests gently on their chest while the other supports their head, symbolizing the weight of their emotions. The background features blurred outlines of barren trees and fallen leaves, set against a muted, overcast sky, enhancing the atmosphere of sadness and contemplation.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['label'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ae7209a-c6f4-4a6a-896f-7cb65a42cbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('Submission_BERT_T5/T5_Test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ce80d32-3c1b-4a74-81e3-07270719c1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.0000\n",
      "ROUGE1 Scores: 0.05345388768111633\n",
      "ROUGE2 Scores: 0.00124628373268266\n",
      "ROUGEL Scores: 0.04654722664428242\n",
      "ROUGELsum Scores: 0.04659231635566289\n",
      "BERTScore (F1): 0.4001\n",
      "METEOR Score: 0.0175\n"
     ]
    }
   ],
   "source": [
    "# from tqdm.auto import tqdm\n",
    "\n",
    "# op_lis_2, lb_lis_2 = [], []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for i, l in tqdm(train_loader, desc=\"train\"):\n",
    "#         generated_ids = best_model.generate(i[\"input_ids\"])\n",
    "#         output_text = tokenizer.batch_decode(\n",
    "#             generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "#         )\n",
    "#         label_text = tokenizer.batch_decode(\n",
    "#             l, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "#         )\n",
    "#         op_lis_2.extend(output_text)\n",
    "#         lb_lis_2.extend(label_text)\n",
    "#     for i, l in tqdm(val_loader, desc=\"val\"):\n",
    "#         generated_ids = best_model.generate(i[\"input_ids\"])\n",
    "#         output_text = tokenizer.batch_decode(\n",
    "#             generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "#         )\n",
    "#         label_text = tokenizer.batch_decode(\n",
    "#             l, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "#         )\n",
    "#         op_lis_2.extend(output_text)\n",
    "#         lb_lis_2.extend(label_text)\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from nltk.translate.meteor_score import single_meteor_score\n",
    "\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "def compute_bleu(predictions, references):\n",
    "    result = bleu.compute(predictions=predictions, references=references)\n",
    "    return result[\"bleu\"]\n",
    "\n",
    "def compute_rouge(predictions, references):\n",
    "    result = rouge.compute(predictions=predictions, references=references)\n",
    "    return result\n",
    "\n",
    "def compute_bertscore(predictions, references):\n",
    "    result = bertscore.compute(predictions=predictions, references=references, model_type=\"bert-base-uncased\")\n",
    "    return np.mean(result[\"f1\"])\n",
    "    \n",
    "def compute_meteor(predictions, references):\n",
    "    tokenized_preds = [pred.split() for pred in predictions]\n",
    "    tokenized_refs = [ref[0].split() for ref in references]\n",
    "    meteor_scores = [single_meteor_score(ref, pred) for ref, pred in zip(tokenized_refs, tokenized_preds)]\n",
    "    return np.mean(meteor_scores)\n",
    "\n",
    "references_ = [[r] for r in test_df['label']]\n",
    "bleu_score = compute_bleu(test_df['output'], references_)\n",
    "rouge_scores = compute_rouge(test_df['output'], references_)\n",
    "bert_score = compute_bertscore(test_df['output'], references_)\n",
    "meteor_score = compute_meteor(test_df['output'], references_)\n",
    "\n",
    "print(f\"BLEU Score: {bleu_score:.4f}\")\n",
    "print(f\"ROUGE1 Scores: {rouge_scores['rouge1']}\")\n",
    "print(f\"ROUGE2 Scores: {rouge_scores['rouge2']}\")\n",
    "print(f\"ROUGEL Scores: {rouge_scores['rougeL']}\")\n",
    "print(f\"ROUGELsum Scores: {rouge_scores['rougeLsum']}\")\n",
    "print(f\"BERTScore (F1): {bert_score:.4f}\")\n",
    "print(f\"METEOR Score: {meteor_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd8161b2-6466-43e9-9006-1bcd59772dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Submission_BERT_T5/T5_Test.txt\", \"w\") as f:\n",
    "    f.write(f\"BLEU Score: {bleu_score:.4f}\\n\")\n",
    "    f.write(f\"ROUGE1 Scores: {rouge_scores['rouge1']}\\n\")\n",
    "    f.write(f\"ROUGE2 Scores: {rouge_scores['rouge2']}\\n\")\n",
    "    f.write(f\"ROUGEL Scores: {rouge_scores['rougeL']}\\n\")\n",
    "    f.write(f\"ROUGELsum Scores: {rouge_scores['rougeLsum']}\\n\")\n",
    "    f.write(f\"BERTScore (F1): {bert_score:.4f}\\n\")\n",
    "    f.write(f\"METEOR Score: {meteor_score:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f91cbeb1-be46-4a00-9fcd-3da3a8f254c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# op_lis_3, lb_lis_3 = [], []\n",
    "# op_lis_3.extend(op_lis_2)\n",
    "# op_lis_3.extend(op_lis)\n",
    "# lb_lis_3.extend(lb_lis_2)\n",
    "# lb_lis_3.extend(lb_lis)\n",
    "\n",
    "df_dataset = HindiDataset(df)\n",
    "\n",
    "df_loader = DataLoader(\n",
    "        df_dataset,\n",
    "        batch_size=8,\n",
    "        collate_fn=partial(collate_fn, tokenizer=tokenizer, device=device)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a357e5b4-d5cb-4731-ad90-7c535fe0c64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ed7d7c31f1475694a83e35ef1cbce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test:   0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# all_df = pd.DataFrame({'output': op_lis_3, 'label': lb_lis_3})\n",
    "# all_df.head(), len(all_df)\n",
    "\n",
    "op_lis, lb_lis = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, l in tqdm(df_loader, desc=\"test\"):\n",
    "        generated_ids = model.generate(i[\"input_ids\"])\n",
    "        output_text = tokenizer.batch_decode(\n",
    "            generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "        )\n",
    "        label_text = tokenizer.batch_decode(\n",
    "            l, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "        )\n",
    "        op_lis.extend(output_text)\n",
    "        lb_lis.extend(label_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e739f59-5b3f-4f36-bc40-92869aed1337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hindirbअधगगगगगगगगगगगगगगगग</td>\n",
       "      <td>The Hindi proverb \"अधजल गगरी छलकत जाय\" transla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hindirbमुँममँममँममँममँममँम</td>\n",
       "      <td>The Hindi proverb \"अपने मुँह मियाँ मिट्ठू बनान...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hindirbहाना translate totoing the of's's's's's</td>\n",
       "      <td>To create a clear and highly specific visualiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hindirbउ उ उ उ उ उ उ उ उ उ उ उ उ उ उ उ उ उ</td>\n",
       "      <td>The Hindi proverb \"अपना उल्लू सीधा करना\" trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hindirbअंगना बरसना translate totoing ins of or...</td>\n",
       "      <td>Certainly! Here is a revised version with a cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>Hindirbहाटी होना translate tototo a orto in. d...</td>\n",
       "      <td>The Hindi proverb 'हेटी होना' translates to \"t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>Hindirbहना (hna)ssssssssssss</td>\n",
       "      <td>The Hindi proverb 'होश की दवा करना' translates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>Hindirbहना translate tototo a orto in. describ...</td>\n",
       "      <td>The Hindi proverb 'होश ठिकाने आना' translates ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>Hindirbत्रिंक होना translate totototototototot...</td>\n",
       "      <td>The Hindi proverb 'त्रिशुंक होना' (Trishanku H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>Hindirbत्राहिना translate tototo a orto a orto...</td>\n",
       "      <td>The Hindi proverb 'त्राहि-त्राहि करना' (Traahi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1277 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 output  \\\n",
       "0                             Hindirbअधगगगगगगगगगगगगगगगग   \n",
       "1                            Hindirbमुँममँममँममँममँममँम   \n",
       "2        Hindirbहाना translate totoing the of's's's's's   \n",
       "3            Hindirbउ उ उ उ उ उ उ उ उ उ उ उ उ उ उ उ उ उ   \n",
       "4     Hindirbअंगना बरसना translate totoing ins of or...   \n",
       "...                                                 ...   \n",
       "1272  Hindirbहाटी होना translate tototo a orto in. d...   \n",
       "1273                       Hindirbहना (hna)ssssssssssss   \n",
       "1274  Hindirbहना translate tototo a orto in. describ...   \n",
       "1275  Hindirbत्रिंक होना translate totototototototot...   \n",
       "1276  Hindirbत्राहिना translate tototo a orto a orto...   \n",
       "\n",
       "                                                  label  \n",
       "0     The Hindi proverb \"अधजल गगरी छलकत जाय\" transla...  \n",
       "1     The Hindi proverb \"अपने मुँह मियाँ मिट्ठू बनान...  \n",
       "2     To create a clear and highly specific visualiz...  \n",
       "3     The Hindi proverb \"अपना उल्लू सीधा करना\" trans...  \n",
       "4     Certainly! Here is a revised version with a cl...  \n",
       "...                                                 ...  \n",
       "1272  The Hindi proverb 'हेटी होना' translates to \"t...  \n",
       "1273  The Hindi proverb 'होश की दवा करना' translates...  \n",
       "1274  The Hindi proverb 'होश ठिकाने आना' translates ...  \n",
       "1275  The Hindi proverb 'त्रिशुंक होना' (Trishanku H...  \n",
       "1276  The Hindi proverb 'त्राहि-त्राहि करना' (Traahi...  \n",
       "\n",
       "[1277 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_df = pd.DataFrame({'output': op_lis, 'label': lb_lis})\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "497c8841-5642-4233-964a-19f377436de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.to_csv('Submission_BERT_T5/T5_allData.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa2fa79b-d9c3-45b1-af80-0467889a4527",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Submission_BERT_T5/T5_allData.txt\", \"w\") as f:\n",
    "    f.write(f\"BLEU Score: {bleu_score:.4f}\\n\")\n",
    "    f.write(f\"ROUGE1 Scores: {rouge_scores['rouge1']}\\n\")\n",
    "    f.write(f\"ROUGE2 Scores: {rouge_scores['rouge2']}\\n\")\n",
    "    f.write(f\"ROUGEL Scores: {rouge_scores['rougeL']}\\n\")\n",
    "    f.write(f\"ROUGELsum Scores: {rouge_scores['rougeLsum']}\\n\")\n",
    "    f.write(f\"BERTScore (F1): {bert_score:.4f}\\n\")\n",
    "    f.write(f\"METEOR Score: {meteor_score:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c07a32-44b0-429a-9077-d873255a7f01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (super_art)",
   "language": "python",
   "name": "super_art"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
