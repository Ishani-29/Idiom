{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3690d6-40bb-4c71-b772-dfcf39f70b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login('hugging_face_token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "277713e8-3b9f-46d4-9b53-a24613309777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeef490b-c5a2-4b0f-a539-df517ca431bc",
   "metadata": {},
   "source": [
    "# Load Model and Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31fc73d6-ae80-4922-8008-26b706837f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 18:06:15.593932: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738753575.619119  282656 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738753575.626609  282656 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-05 18:06:15.650540: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(128128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(128128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(128128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=128128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"rahular/varta-t5\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"rahular/varta-t5\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07994b0-90b2-48f0-98e0-f722525cb266",
   "metadata": {},
   "source": [
    "# Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc02c7ee-6cc3-4800-a843-b034e585f1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Proverb</th>\n",
       "      <th>Final_Human_Annotation</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡§Ö‡§ß‡§ú‡§≤ ‡§ó‡§ó‡§∞‡•Ä ‡§õ‡§≤‡§ï‡§§ ‡§ú‡§æ‡§Ø‡•§</td>\n",
       "      <td>The Hindi proverb \"‡§Ö‡§ß‡§ú‡§≤ ‡§ó‡§ó‡§∞‡•Ä ‡§õ‡§≤‡§ï‡§§ ‡§ú‡§æ‡§Ø\" transla...</td>\n",
       "      <td>hindi_img/0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡§Ö‡§™‡§®‡•á ‡§Æ‡•Å‡§Å‡§π ‡§Æ‡§ø‡§Ø‡§æ‡§Å ‡§Æ‡§ø‡§ü‡•ç‡§†‡•Ç ‡§¨‡§®‡§æ‡§®‡§æ‡•§</td>\n",
       "      <td>The Hindi proverb \"‡§Ö‡§™‡§®‡•á ‡§Æ‡•Å‡§Å‡§π ‡§Æ‡§ø‡§Ø‡§æ‡§Å ‡§Æ‡§ø‡§ü‡•ç‡§†‡•Ç ‡§¨‡§®‡§æ...</td>\n",
       "      <td>hindi_img/1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡§Ö‡§™‡§®‡•á ‡§π‡§æ‡§• ‡§Æ‡•á‡§Ç ‡§Ö‡§™‡§®‡§æ ‡§≠‡§æ‡§ó‡•ç‡§Ø ‡§π‡•ã‡§®‡§æ‡•§</td>\n",
       "      <td>To create a clear and highly specific visualiz...</td>\n",
       "      <td>hindi_img/2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡§Ö‡§™‡§®‡§æ ‡§â‡§≤‡•ç‡§≤‡•Ç ‡§∏‡•Ä‡§ß‡§æ ‡§ï‡§∞‡§®‡§æ‡•§</td>\n",
       "      <td>The Hindi proverb \"‡§Ö‡§™‡§®‡§æ ‡§â‡§≤‡•ç‡§≤‡•Ç ‡§∏‡•Ä‡§ß‡§æ ‡§ï‡§∞‡§®‡§æ\" trans...</td>\n",
       "      <td>hindi_img/3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‡§Ö‡§Å‡§ó‡§æ‡§∞‡•á ‡§¨‡§∞‡§∏‡§®‡§æ</td>\n",
       "      <td>Certainly! Here is a revised version with a cl...</td>\n",
       "      <td>hindi_img/4.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Actual Proverb  \\\n",
       "0            ‡§Ö‡§ß‡§ú‡§≤ ‡§ó‡§ó‡§∞‡•Ä ‡§õ‡§≤‡§ï‡§§ ‡§ú‡§æ‡§Ø‡•§   \n",
       "1  ‡§Ö‡§™‡§®‡•á ‡§Æ‡•Å‡§Å‡§π ‡§Æ‡§ø‡§Ø‡§æ‡§Å ‡§Æ‡§ø‡§ü‡•ç‡§†‡•Ç ‡§¨‡§®‡§æ‡§®‡§æ‡•§   \n",
       "2  ‡§Ö‡§™‡§®‡•á ‡§π‡§æ‡§• ‡§Æ‡•á‡§Ç ‡§Ö‡§™‡§®‡§æ ‡§≠‡§æ‡§ó‡•ç‡§Ø ‡§π‡•ã‡§®‡§æ‡•§   \n",
       "3          ‡§Ö‡§™‡§®‡§æ ‡§â‡§≤‡•ç‡§≤‡•Ç ‡§∏‡•Ä‡§ß‡§æ ‡§ï‡§∞‡§®‡§æ‡•§   \n",
       "4                   ‡§Ö‡§Å‡§ó‡§æ‡§∞‡•á ‡§¨‡§∞‡§∏‡§®‡§æ   \n",
       "\n",
       "                              Final_Human_Annotation         img_path  \n",
       "0  The Hindi proverb \"‡§Ö‡§ß‡§ú‡§≤ ‡§ó‡§ó‡§∞‡•Ä ‡§õ‡§≤‡§ï‡§§ ‡§ú‡§æ‡§Ø\" transla...  hindi_img/0.png  \n",
       "1   The Hindi proverb \"‡§Ö‡§™‡§®‡•á ‡§Æ‡•Å‡§Å‡§π ‡§Æ‡§ø‡§Ø‡§æ‡§Å ‡§Æ‡§ø‡§ü‡•ç‡§†‡•Ç ‡§¨‡§®‡§æ...  hindi_img/1.png  \n",
       "2  To create a clear and highly specific visualiz...  hindi_img/2.png  \n",
       "3  The Hindi proverb \"‡§Ö‡§™‡§®‡§æ ‡§â‡§≤‡•ç‡§≤‡•Ç ‡§∏‡•Ä‡§ß‡§æ ‡§ï‡§∞‡§®‡§æ\" trans...  hindi_img/3.png  \n",
       "4  Certainly! Here is a revised version with a cl...  hindi_img/4.png  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "\n",
    "df = pd.read_csv('training_df.csv')\n",
    "df = df.drop('Descriptive Meaning by ChatGPT', axis=1)\n",
    "df['img_path'] = ''\n",
    "for i in range(len(df)):\n",
    "    df.loc[i,'img_path'] = 'hindi_img/'+str(i)+'.png'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dcb2d8d-ad9a-49ae-82fe-91656def9f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((816, 3), (205, 3), (256, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(temp_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49cd77a-6917-43c9-a4f8-4fe7cf1dc466",
   "metadata": {},
   "source": [
    "## Try Tokenizer & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27dcadd9-e3db-445d-9441-3b0724c592dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: What is meaning of proverb named ‡§∞‡•á‡§≤-‡§™‡•á‡§≤ ‡§π‡•ã‡§®‡§æ ?\n",
      "\n",
      "Label: Certainly! Here's a more specific description for the visual representation:\n",
      "\n",
      "Imagine a bustling train station platform during peak hours. The scene is packed with a dense crowd of people, each person tightly packed against the others. Individuals are jostling to get closer to the edge of the platform, where an incoming train is arriving. A variety of people are shown: a woman clutching her bag tightly, a man looking at his watch anxiously, a group of school children trying to navigate through the throng, and a vendor holding a tray of snacks high above his shoulder to avoid the crush. The expressions on their faces range from impatience to frustration, capturing the chaos and urgency of the moment. In the background, the blurred motion of the approaching train adds to the sense of hustle and frenzy.\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"What is meaning of proverb named \" + train_df.loc[0,'Actual Proverb'] + \" ?\", return_tensors=\"pt\")\n",
    "labels = tokenizer(train_df.loc[0, \"Final_Human_Annotation\"], return_tensors=\"pt\").input_ids\n",
    "\n",
    "print(\"Input:\", \"What is meaning of proverb named \" + train_df.loc[0,'Actual Proverb'] + \" ?\\n\")\n",
    "print(\"Label:\", train_df.loc[0, \"Final_Human_Annotation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5fea58b-7406-4f5a-8439-bef3ed3ce555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is meaning of proverb named ‡§∞‡•á‡§≤-‡§™‡•á‡§≤ ‡§π‡•ã‡§®‡§æ ?</s>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6714527b-ac75-4fb3-8f71-28abc4909a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Certainly! Here's a more specific description for the visual representation: Imagine a bustling train station platform during peak hours. The scene is packed with a dense crowd of people, each person tightly packed against the others. Individuals are jostling to get closer to the edge of the platform, where an incoming train is arriving. A variety of people are shown: a woman clutching her bag tightly, a man looking at his watch anxiously, a group of school children trying to navigate through the throng, and a vendor holding a tray of snacks high above his shoulder to avoid the crush. The expressions on their faces range from impatience to frustration, capturing the chaos and urgency of the moment. In the background, the blurred motion of the approaching train adds to the sense of hustle and frenzy.</s>\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ed0673-1184-4a89-8369-2b1c0c70bda6",
   "metadata": {},
   "source": [
    "## custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdd81edb-94f1-446b-bc93-3a86bacfe896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "class HindiDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = {\n",
    "            \"texts_input\": self.df.loc[idx, 'Actual Proverb'],\n",
    "            'texts_label': self.df.loc[idx, 'Final_Human_Annotation']\n",
    "        }\n",
    "        return row\n",
    "\n",
    "def collate_fn(batch, tokenizer, device):\n",
    "    input_lis = [r['texts_input'] for r in batch]\n",
    "    label_lis = [r['texts_label'] for r in batch]\n",
    "    inputs = tokenizer(\n",
    "        text=input_lis, return_tensors=\"pt\", padding=\"max_length\", max_length=512, truncation=True\n",
    "    )\n",
    "    inputs.pop('token_type_ids', None)\n",
    "    inputs = {key: valu.to(device) for key, valu in inputs.items()}\n",
    "    labels_ids = tokenizer(\n",
    "        text=label_lis, return_tensors=\"pt\", padding=\"max_length\", max_length=512, truncation=True\n",
    "    ).input_ids\n",
    "    labels_ids = labels_ids.to(device)\n",
    "    return inputs, labels_ids\n",
    "    \n",
    "train_dataset = HindiDataset(train_df)\n",
    "val_dataset = HindiDataset(val_df)\n",
    "test_dataset = HindiDataset(test_df)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=8,\n",
    "        collate_fn=partial(collate_fn, tokenizer=tokenizer, device=device)\n",
    "    )\n",
    "val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=4,\n",
    "        collate_fn=partial(collate_fn, tokenizer=tokenizer, device=device)\n",
    "    )\n",
    "test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=4,\n",
    "        collate_fn=partial(collate_fn, tokenizer=tokenizer, device=device)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adeb366-6199-4299-a108-99a4c7bbed05",
   "metadata": {},
   "source": [
    "# Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "621e4592-bfcd-47ce-ab44-30c88377fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "epochs = 15\n",
    "train_steps = len(train_loader) * epochs\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=int(0.1 * train_steps), num_training_steps=train_steps\n",
    ")\n",
    "loss_fct = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2209345-f7cc-47e4-a5a9-3244c58f0bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69778fccc14f4800950fcdfebea63fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Epoch 1 - Training Loss: 8.9240\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3186792ee40d4eafa5e875e7da902dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 1 - Validation Loss: 6.8760\n",
      "üíæ Best model saved at Epoch 1\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb019031f2a4f3fa88b926526995504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 2:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Epoch 2 - Training Loss: 6.8700\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8877a531e54e48fb917697c0d92d909f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 2 - Validation Loss: 5.9959\n",
      "üíæ Best model saved at Epoch 2\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253338a4f78742a2b09ca72939208fd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 3:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Epoch 3 - Training Loss: 6.2348\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2fa51640ad04bfc9bbe9c03c123b1b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 3 - Validation Loss: 5.5270\n",
      "üíæ Best model saved at Epoch 3\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda4848815f84ca5af2812fd33f9423e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 4:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Epoch 4 - Training Loss: 5.8324\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde541aad09c4c68a6dcc50b400eee6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 4 - Validation Loss: 5.2449\n",
      "üíæ Best model saved at Epoch 4\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d930150aea76407fa881cd21cbb68e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 5:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Epoch 5 - Training Loss: 5.5762\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a275b1b40e48d4920ac59ea8f74a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 5 - Validation Loss: 5.0645\n",
      "üíæ Best model saved at Epoch 5\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356222d871a9447eb3a8df7426ed4344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 6:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Epoch 6 - Training Loss: 5.3949\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79afa56bd7344479b995bf87ffd1ca35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 6 - Validation Loss: 4.9346\n",
      "üíæ Best model saved at Epoch 6\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6481f7518841e0bb24d22186a8d62f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 7:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Epoch 7 - Training Loss: 5.2579\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba80560e138540fbaff0920dd3f8753c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 7 - Validation Loss: 4.8349\n",
      "üíæ Best model saved at Epoch 7\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6939dbf67b477086eb9e3da3986727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 8:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Epoch 8 - Training Loss: 5.1578\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5acc418de78d43f6aa43a97ee6889468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 8 - Validation Loss: 4.7626\n",
      "üíæ Best model saved at Epoch 8\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a047a91d4345e7b48b3d3cc6c5e71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 9:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Epoch 9 - Training Loss: 5.0878\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a741549cc89a468daf1c5e54412b0172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 9 - Validation Loss: 4.7081\n",
      "üíæ Best model saved at Epoch 9\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b474d187c4f54b25a73719c891aaf6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 10:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Epoch 10 - Training Loss: 5.0263\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9137be4d6f184aaabcc38234a2c2c246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 10 - Validation Loss: 4.6665\n",
      "üíæ Best model saved at Epoch 10\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec6ae2a694049a298adc5c0e20043d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 11:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Epoch 11 - Training Loss: 4.9886\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3640eca64b746a8a2109f6a920d3a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 11 - Validation Loss: 4.6389\n",
      "üíæ Best model saved at Epoch 11\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f083841c06494487b08e382da7956d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 12:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Epoch 12 - Training Loss: 4.9562\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6653a115de31448d927e587c7058bd76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 12 - Validation Loss: 4.6219\n",
      "üíæ Best model saved at Epoch 12\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499354a0da774d4582d816bf8b7aa3ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 13:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Epoch 13 - Training Loss: 4.9401\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3056d18b77614f4d86bd4dae733ef81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 13 - Validation Loss: 4.6131\n",
      "üíæ Best model saved at Epoch 13\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5757399c03c04d999453f8281a943e3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 14:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Epoch 14 - Training Loss: 4.9294\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d435d7f4bf742a28fbe0ea8dd047c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 14 - Validation Loss: 4.6099\n",
      "üíæ Best model saved at Epoch 14\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01212e1d36634ff28661e9b50824f70f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 15:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Epoch 15 - Training Loss: 4.9302\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add79cb63d1240d49605708f921bf055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 15 - Validation Loss: 4.6094\n",
      "üíæ Best model saved at Epoch 15\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_progress = tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}\", leave=True, position=0)\n",
    "    for input_ids, labels in train_progress:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(\n",
    "            input_ids=input_ids['input_ids'],\n",
    "            attention_mask=input_ids['attention_mask'],\n",
    "            labels=labels\n",
    "        )\n",
    "        logits = outputs.logits  \n",
    "        shift_logits = logits[:, :-1, :].contiguous().view(-1, logits.size(-1))\n",
    "        shift_labels = labels[:, 1:].contiguous().view(-1)\n",
    "        loss = loss_fct(shift_logits, shift_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        running_loss += loss.item()\n",
    "        train_progress.set_postfix(loss=loss.item())\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    tqdm.write(f\"\\nüéØ Epoch {epoch + 1} - Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_progress = tqdm(val_loader, desc=\"üîç Validation\", leave=True, position=0)\n",
    "    with torch.no_grad():\n",
    "        for input_ids, labels in val_progress:\n",
    "            outputs = model(\n",
    "                input_ids=input_ids['input_ids'],\n",
    "                attention_mask=input_ids['attention_mask'],\n",
    "                labels=labels\n",
    "            )\n",
    "            logits = outputs.logits  \n",
    "            shift_logits = logits[:, :-1, :].contiguous().view(-1, logits.size(-1))\n",
    "            shift_labels = labels[:, 1:].contiguous().view(-1)\n",
    "            loss = loss_fct(shift_logits, shift_labels)\n",
    "            val_loss += loss.item()\n",
    "            val_progress.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    tqdm.write(f\"‚úÖ Epoch {epoch + 1} - Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        os.makedirs(\"art_t5/\", exist_ok=True)\n",
    "        model.save_pretrained(\"art_t5/best_model\", from_pt=True)\n",
    "        tqdm.write(f\"üíæ Best model saved at Epoch {epoch + 1}\")\n",
    "    tqdm.write(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8281d63c-3ffb-4500-a58f-20a89eecd7c0",
   "metadata": {},
   "source": [
    "# load best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3be3691e-e7ad-425d-b99a-1744781ca3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "\n",
    "# best_model = T5ForConditionalGeneration.from_pretrained(\"./art_t5/best_model/\")\n",
    "# best_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12827e6-0ffe-4cd3-90d4-6b410199abf6",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "477e96cf-3c69-49da-b3df-43ceb3087937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e2879196704f978f6cccfa4249fcd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "op_lis, lb_lis = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, l in tqdm(test_loader, desc=\"test\"):\n",
    "        generated_ids = model.generate(i[\"input_ids\"])\n",
    "        output_text = tokenizer.batch_decode(\n",
    "            generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "        )\n",
    "        label_text = tokenizer.batch_decode(\n",
    "            l, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "        )\n",
    "        op_lis.extend(output_text)\n",
    "        lb_lis.extend(label_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff2ed3c1-7275-4876-8c75-ff348787488e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hindirb‡§†‡§®‡§æ translate tototo a orto a orto a or...</td>\n",
       "      <td>The Hindi proverb '‡§†‡§Ç‡§°‡•Ä ‡§Ü‡§π‡•á‡§Ç ‡§≠‡§∞‡§®‡§æ' translates ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hindirb ‡§™‡§§‡•ç‡§•‡§∞ ‡§≤‡§ï‡•Ä‡§∞ (stonestick)shor)shorsshorss</td>\n",
       "      <td>The Hindi proverb '‡§™‡§§‡•ç‡§•‡§∞ ‡§ï‡•Ä ‡§≤‡§ï‡•Ä‡§∞' translates t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hindirb ‡§Æ‡§ï‡•ç‡§ñ‡§® ‡§≤‡§ó‡§æ‡§®‡§æ translate totoing oring so...</td>\n",
       "      <td>The Hindi proverb '‡§Æ‡§ï‡•ç‡§ñ‡§® ‡§≤‡§ó‡§æ‡§®‡§æ' translates to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hindirb‡§ö‡§Æ‡§®‡§æ translate tototo a of a or a, a or...</td>\n",
       "      <td>To visually represent this proverb, consider a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hindirb‡§è‡§ï‡§®‡§æ‡§Å‡§®‡§æ translate tototo a orto in.toto...</td>\n",
       "      <td>The Hindi proverb '‡§Ö‡§ï‡•á‡§≤‡§æ ‡§π‡§Å‡§∏‡§§‡§æ ‡§≠‡§≤‡§æ ‡§® ‡§∞‡•ã‡§§‡§æ ‡§≠‡§≤‡§æ‡•§...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Hindirb‡§∏‡§æ‡§™ ‡§¶‡•Ç‡§ß‡§®‡§æ translate tototo milk in. des...</td>\n",
       "      <td>The proverb '‡§∏‡§æ‡§Å‡§™ ‡§ï‡•ã ‡§¶‡•Ç‡§ß ‡§™‡§ø‡§≤‡§æ‡§®‡§æ' translates to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Hindirb‡§∏‡§ú‡§¨‡§æ‡§ó ‡§¶‡§ø‡§ñ‡§æ'sssssssssssss</td>\n",
       "      <td>Certainly! I'll refine the visualization to ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>Hindirb‡§§‡§æ‡§µ ‡§Ü‡§®‡§æ translate totototototototototot...</td>\n",
       "      <td>The Hindi proverb '‡§§‡§æ‡§µ ‡§Ü‡§®‡§æ' translates to \"to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>Hindirb‡§ß‡§®‡§æ translate tototo a orto in. describ...</td>\n",
       "      <td>The Hindi proverb '‡§¶‡•É‡§∑‡•ç‡§ü‡§ø ‡§´‡§ø‡§∞‡§®‡§æ' translates to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>Hindirb‡§¢ ‡§™‡§°‡§º‡§®‡§æ translate tototo a orto in. des...</td>\n",
       "      <td>The Hindi proverb '‡§¨‡§∞‡§∏ ‡§™‡§°‡§º‡§®‡§æ' translates to 't...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                output  \\\n",
       "0    Hindirb‡§†‡§®‡§æ translate tototo a orto a orto a or...   \n",
       "1      Hindirb ‡§™‡§§‡•ç‡§•‡§∞ ‡§≤‡§ï‡•Ä‡§∞ (stonestick)shor)shorsshorss   \n",
       "2    Hindirb ‡§Æ‡§ï‡•ç‡§ñ‡§® ‡§≤‡§ó‡§æ‡§®‡§æ translate totoing oring so...   \n",
       "3    Hindirb‡§ö‡§Æ‡§®‡§æ translate tototo a of a or a, a or...   \n",
       "4    Hindirb‡§è‡§ï‡§®‡§æ‡§Å‡§®‡§æ translate tototo a orto in.toto...   \n",
       "..                                                 ...   \n",
       "251  Hindirb‡§∏‡§æ‡§™ ‡§¶‡•Ç‡§ß‡§®‡§æ translate tototo milk in. des...   \n",
       "252                    Hindirb‡§∏‡§ú‡§¨‡§æ‡§ó ‡§¶‡§ø‡§ñ‡§æ'sssssssssssss   \n",
       "253  Hindirb‡§§‡§æ‡§µ ‡§Ü‡§®‡§æ translate totototototototototot...   \n",
       "254  Hindirb‡§ß‡§®‡§æ translate tototo a orto in. describ...   \n",
       "255  Hindirb‡§¢ ‡§™‡§°‡§º‡§®‡§æ translate tototo a orto in. des...   \n",
       "\n",
       "                                                 label  \n",
       "0    The Hindi proverb '‡§†‡§Ç‡§°‡•Ä ‡§Ü‡§π‡•á‡§Ç ‡§≠‡§∞‡§®‡§æ' translates ...  \n",
       "1    The Hindi proverb '‡§™‡§§‡•ç‡§•‡§∞ ‡§ï‡•Ä ‡§≤‡§ï‡•Ä‡§∞' translates t...  \n",
       "2    The Hindi proverb '‡§Æ‡§ï‡•ç‡§ñ‡§® ‡§≤‡§ó‡§æ‡§®‡§æ' translates to ...  \n",
       "3    To visually represent this proverb, consider a...  \n",
       "4    The Hindi proverb '‡§Ö‡§ï‡•á‡§≤‡§æ ‡§π‡§Å‡§∏‡§§‡§æ ‡§≠‡§≤‡§æ ‡§® ‡§∞‡•ã‡§§‡§æ ‡§≠‡§≤‡§æ‡•§...  \n",
       "..                                                 ...  \n",
       "251  The proverb '‡§∏‡§æ‡§Å‡§™ ‡§ï‡•ã ‡§¶‡•Ç‡§ß ‡§™‡§ø‡§≤‡§æ‡§®‡§æ' translates to...  \n",
       "252  Certainly! I'll refine the visualization to ma...  \n",
       "253  The Hindi proverb '‡§§‡§æ‡§µ ‡§Ü‡§®‡§æ' translates to \"to ...  \n",
       "254  The Hindi proverb '‡§¶‡•É‡§∑‡•ç‡§ü‡§ø ‡§´‡§ø‡§∞‡§®‡§æ' translates to...  \n",
       "255  The Hindi proverb '‡§¨‡§∞‡§∏ ‡§™‡§°‡§º‡§®‡§æ' translates to 't...  \n",
       "\n",
       "[256 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df = pd.DataFrame({'output': op_lis, 'label': lb_lis})\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d38127b-d36a-4bb7-9e10-254c54d16e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hindirb‡§†‡§®‡§æ translate tototo a orto a orto a orto a orto'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['output'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0754bb4-a4f7-4647-aea6-860008022269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Hindi proverb '‡§†‡§Ç‡§°‡•Ä ‡§Ü‡§π‡•á‡§Ç ‡§≠‡§∞‡§®‡§æ' translates to 'sighing deeply' in English. It signifies a state of deep sorrow, regret, or longing. The imagery associated with this proverb can be visualized with an individual sitting on a wooden bench in a dimly lit park, under the soft glow of a solitary streetlamp. The person, wearing a dark, weathered coat, is exhaling slowly with a melancholic expression. One hand rests gently on their chest while the other supports their head, symbolizing the weight of their emotions. The background features blurred outlines of barren trees and fallen leaves, set against a muted, overcast sky, enhancing the atmosphere of sadness and contemplation.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['label'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ae7209a-c6f4-4a6a-896f-7cb65a42cbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('Submission_BERT_T5/T5_Test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ce80d32-3c1b-4a74-81e3-07270719c1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.0000\n",
      "ROUGE1 Scores: 0.05345388768111633\n",
      "ROUGE2 Scores: 0.00124628373268266\n",
      "ROUGEL Scores: 0.04654722664428242\n",
      "ROUGELsum Scores: 0.04659231635566289\n",
      "BERTScore (F1): 0.4001\n",
      "METEOR Score: 0.0175\n"
     ]
    }
   ],
   "source": [
    "# from tqdm.auto import tqdm\n",
    "\n",
    "# op_lis_2, lb_lis_2 = [], []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for i, l in tqdm(train_loader, desc=\"train\"):\n",
    "#         generated_ids = best_model.generate(i[\"input_ids\"])\n",
    "#         output_text = tokenizer.batch_decode(\n",
    "#             generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "#         )\n",
    "#         label_text = tokenizer.batch_decode(\n",
    "#             l, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "#         )\n",
    "#         op_lis_2.extend(output_text)\n",
    "#         lb_lis_2.extend(label_text)\n",
    "#     for i, l in tqdm(val_loader, desc=\"val\"):\n",
    "#         generated_ids = best_model.generate(i[\"input_ids\"])\n",
    "#         output_text = tokenizer.batch_decode(\n",
    "#             generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "#         )\n",
    "#         label_text = tokenizer.batch_decode(\n",
    "#             l, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "#         )\n",
    "#         op_lis_2.extend(output_text)\n",
    "#         lb_lis_2.extend(label_text)\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from nltk.translate.meteor_score import single_meteor_score\n",
    "\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "def compute_bleu(predictions, references):\n",
    "    result = bleu.compute(predictions=predictions, references=references)\n",
    "    return result[\"bleu\"]\n",
    "\n",
    "def compute_rouge(predictions, references):\n",
    "    result = rouge.compute(predictions=predictions, references=references)\n",
    "    return result\n",
    "\n",
    "def compute_bertscore(predictions, references):\n",
    "    result = bertscore.compute(predictions=predictions, references=references, model_type=\"bert-base-uncased\")\n",
    "    return np.mean(result[\"f1\"])\n",
    "    \n",
    "def compute_meteor(predictions, references):\n",
    "    tokenized_preds = [pred.split() for pred in predictions]\n",
    "    tokenized_refs = [ref[0].split() for ref in references]\n",
    "    meteor_scores = [single_meteor_score(ref, pred) for ref, pred in zip(tokenized_refs, tokenized_preds)]\n",
    "    return np.mean(meteor_scores)\n",
    "\n",
    "references_ = [[r] for r in test_df['label']]\n",
    "bleu_score = compute_bleu(test_df['output'], references_)\n",
    "rouge_scores = compute_rouge(test_df['output'], references_)\n",
    "bert_score = compute_bertscore(test_df['output'], references_)\n",
    "meteor_score = compute_meteor(test_df['output'], references_)\n",
    "\n",
    "print(f\"BLEU Score: {bleu_score:.4f}\")\n",
    "print(f\"ROUGE1 Scores: {rouge_scores['rouge1']}\")\n",
    "print(f\"ROUGE2 Scores: {rouge_scores['rouge2']}\")\n",
    "print(f\"ROUGEL Scores: {rouge_scores['rougeL']}\")\n",
    "print(f\"ROUGELsum Scores: {rouge_scores['rougeLsum']}\")\n",
    "print(f\"BERTScore (F1): {bert_score:.4f}\")\n",
    "print(f\"METEOR Score: {meteor_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd8161b2-6466-43e9-9006-1bcd59772dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Submission_BERT_T5/T5_Test.txt\", \"w\") as f:\n",
    "    f.write(f\"BLEU Score: {bleu_score:.4f}\\n\")\n",
    "    f.write(f\"ROUGE1 Scores: {rouge_scores['rouge1']}\\n\")\n",
    "    f.write(f\"ROUGE2 Scores: {rouge_scores['rouge2']}\\n\")\n",
    "    f.write(f\"ROUGEL Scores: {rouge_scores['rougeL']}\\n\")\n",
    "    f.write(f\"ROUGELsum Scores: {rouge_scores['rougeLsum']}\\n\")\n",
    "    f.write(f\"BERTScore (F1): {bert_score:.4f}\\n\")\n",
    "    f.write(f\"METEOR Score: {meteor_score:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f91cbeb1-be46-4a00-9fcd-3da3a8f254c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# op_lis_3, lb_lis_3 = [], []\n",
    "# op_lis_3.extend(op_lis_2)\n",
    "# op_lis_3.extend(op_lis)\n",
    "# lb_lis_3.extend(lb_lis_2)\n",
    "# lb_lis_3.extend(lb_lis)\n",
    "\n",
    "df_dataset = HindiDataset(df)\n",
    "\n",
    "df_loader = DataLoader(\n",
    "        df_dataset,\n",
    "        batch_size=8,\n",
    "        collate_fn=partial(collate_fn, tokenizer=tokenizer, device=device)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a357e5b4-d5cb-4731-ad90-7c535fe0c64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ed7d7c31f1475694a83e35ef1cbce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test:   0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# all_df = pd.DataFrame({'output': op_lis_3, 'label': lb_lis_3})\n",
    "# all_df.head(), len(all_df)\n",
    "\n",
    "op_lis, lb_lis = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, l in tqdm(df_loader, desc=\"test\"):\n",
    "        generated_ids = model.generate(i[\"input_ids\"])\n",
    "        output_text = tokenizer.batch_decode(\n",
    "            generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "        )\n",
    "        label_text = tokenizer.batch_decode(\n",
    "            l, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "        )\n",
    "        op_lis.extend(output_text)\n",
    "        lb_lis.extend(label_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e739f59-5b3f-4f36-bc40-92869aed1337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hindirb‡§Ö‡§ß‡§ó‡§ó‡§ó‡§ó‡§ó‡§ó‡§ó‡§ó‡§ó‡§ó‡§ó‡§ó‡§ó‡§ó‡§ó‡§ó</td>\n",
       "      <td>The Hindi proverb \"‡§Ö‡§ß‡§ú‡§≤ ‡§ó‡§ó‡§∞‡•Ä ‡§õ‡§≤‡§ï‡§§ ‡§ú‡§æ‡§Ø\" transla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hindirb‡§Æ‡•Å‡§Å‡§Æ‡§Æ‡§Å‡§Æ‡§Æ‡§Å‡§Æ‡§Æ‡§Å‡§Æ‡§Æ‡§Å‡§Æ‡§Æ‡§Å‡§Æ</td>\n",
       "      <td>The Hindi proverb \"‡§Ö‡§™‡§®‡•á ‡§Æ‡•Å‡§Å‡§π ‡§Æ‡§ø‡§Ø‡§æ‡§Å ‡§Æ‡§ø‡§ü‡•ç‡§†‡•Ç ‡§¨‡§®‡§æ‡§®...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hindirb‡§π‡§æ‡§®‡§æ translate totoing the of's's's's's</td>\n",
       "      <td>To create a clear and highly specific visualiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hindirb‡§â ‡§â ‡§â ‡§â ‡§â ‡§â ‡§â ‡§â ‡§â ‡§â ‡§â ‡§â ‡§â ‡§â ‡§â ‡§â ‡§â ‡§â</td>\n",
       "      <td>The Hindi proverb \"‡§Ö‡§™‡§®‡§æ ‡§â‡§≤‡•ç‡§≤‡•Ç ‡§∏‡•Ä‡§ß‡§æ ‡§ï‡§∞‡§®‡§æ\" trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hindirb‡§Ö‡§Ç‡§ó‡§®‡§æ ‡§¨‡§∞‡§∏‡§®‡§æ translate totoing ins of or...</td>\n",
       "      <td>Certainly! Here is a revised version with a cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>Hindirb‡§π‡§æ‡§ü‡•Ä ‡§π‡•ã‡§®‡§æ translate tototo a orto in. d...</td>\n",
       "      <td>The Hindi proverb '‡§π‡•á‡§ü‡•Ä ‡§π‡•ã‡§®‡§æ' translates to \"t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>Hindirb‡§π‡§®‡§æ (hna)ssssssssssss</td>\n",
       "      <td>The Hindi proverb '‡§π‡•ã‡§∂ ‡§ï‡•Ä ‡§¶‡§µ‡§æ ‡§ï‡§∞‡§®‡§æ' translates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>Hindirb‡§π‡§®‡§æ translate tototo a orto in. describ...</td>\n",
       "      <td>The Hindi proverb '‡§π‡•ã‡§∂ ‡§†‡§ø‡§ï‡§æ‡§®‡•á ‡§Ü‡§®‡§æ' translates ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>Hindirb‡§§‡•ç‡§∞‡§ø‡§Ç‡§ï ‡§π‡•ã‡§®‡§æ translate totototototototot...</td>\n",
       "      <td>The Hindi proverb '‡§§‡•ç‡§∞‡§ø‡§∂‡•Å‡§Ç‡§ï ‡§π‡•ã‡§®‡§æ' (Trishanku H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>Hindirb‡§§‡•ç‡§∞‡§æ‡§π‡§ø‡§®‡§æ translate tototo a orto a orto...</td>\n",
       "      <td>The Hindi proverb '‡§§‡•ç‡§∞‡§æ‡§π‡§ø-‡§§‡•ç‡§∞‡§æ‡§π‡§ø ‡§ï‡§∞‡§®‡§æ' (Traahi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1277 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 output  \\\n",
       "0                             Hindirb‡§Ö‡§ß‡§ó‡§ó‡§ó‡§ó‡§ó‡§ó‡§ó‡§ó‡§ó‡§ó‡§ó‡§ó‡§ó‡§ó‡§ó‡§ó   \n",
       "1                            Hindirb‡§Æ‡•Å‡§Å‡§Æ‡§Æ‡§Å‡§Æ‡§Æ‡§Å‡§Æ‡§Æ‡§Å‡§Æ‡§Æ‡§Å‡§Æ‡§Æ‡§Å‡§Æ   \n",
       "2        Hindirb‡§π‡§æ‡§®‡§æ translate totoing the of's's's's's   \n",
       "3            Hindirb‡§â ‡§â ‡§â ‡§â ‡§â ‡§â ‡§â ‡§â ‡§â ‡§â ‡§â ‡§â ‡§â ‡§â ‡§â ‡§â ‡§â ‡§â   \n",
       "4     Hindirb‡§Ö‡§Ç‡§ó‡§®‡§æ ‡§¨‡§∞‡§∏‡§®‡§æ translate totoing ins of or...   \n",
       "...                                                 ...   \n",
       "1272  Hindirb‡§π‡§æ‡§ü‡•Ä ‡§π‡•ã‡§®‡§æ translate tototo a orto in. d...   \n",
       "1273                       Hindirb‡§π‡§®‡§æ (hna)ssssssssssss   \n",
       "1274  Hindirb‡§π‡§®‡§æ translate tototo a orto in. describ...   \n",
       "1275  Hindirb‡§§‡•ç‡§∞‡§ø‡§Ç‡§ï ‡§π‡•ã‡§®‡§æ translate totototototototot...   \n",
       "1276  Hindirb‡§§‡•ç‡§∞‡§æ‡§π‡§ø‡§®‡§æ translate tototo a orto a orto...   \n",
       "\n",
       "                                                  label  \n",
       "0     The Hindi proverb \"‡§Ö‡§ß‡§ú‡§≤ ‡§ó‡§ó‡§∞‡•Ä ‡§õ‡§≤‡§ï‡§§ ‡§ú‡§æ‡§Ø\" transla...  \n",
       "1     The Hindi proverb \"‡§Ö‡§™‡§®‡•á ‡§Æ‡•Å‡§Å‡§π ‡§Æ‡§ø‡§Ø‡§æ‡§Å ‡§Æ‡§ø‡§ü‡•ç‡§†‡•Ç ‡§¨‡§®‡§æ‡§®...  \n",
       "2     To create a clear and highly specific visualiz...  \n",
       "3     The Hindi proverb \"‡§Ö‡§™‡§®‡§æ ‡§â‡§≤‡•ç‡§≤‡•Ç ‡§∏‡•Ä‡§ß‡§æ ‡§ï‡§∞‡§®‡§æ\" trans...  \n",
       "4     Certainly! Here is a revised version with a cl...  \n",
       "...                                                 ...  \n",
       "1272  The Hindi proverb '‡§π‡•á‡§ü‡•Ä ‡§π‡•ã‡§®‡§æ' translates to \"t...  \n",
       "1273  The Hindi proverb '‡§π‡•ã‡§∂ ‡§ï‡•Ä ‡§¶‡§µ‡§æ ‡§ï‡§∞‡§®‡§æ' translates...  \n",
       "1274  The Hindi proverb '‡§π‡•ã‡§∂ ‡§†‡§ø‡§ï‡§æ‡§®‡•á ‡§Ü‡§®‡§æ' translates ...  \n",
       "1275  The Hindi proverb '‡§§‡•ç‡§∞‡§ø‡§∂‡•Å‡§Ç‡§ï ‡§π‡•ã‡§®‡§æ' (Trishanku H...  \n",
       "1276  The Hindi proverb '‡§§‡•ç‡§∞‡§æ‡§π‡§ø-‡§§‡•ç‡§∞‡§æ‡§π‡§ø ‡§ï‡§∞‡§®‡§æ' (Traahi...  \n",
       "\n",
       "[1277 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_df = pd.DataFrame({'output': op_lis, 'label': lb_lis})\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "497c8841-5642-4233-964a-19f377436de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.to_csv('Submission_BERT_T5/T5_allData.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa2fa79b-d9c3-45b1-af80-0467889a4527",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Submission_BERT_T5/T5_allData.txt\", \"w\") as f:\n",
    "    f.write(f\"BLEU Score: {bleu_score:.4f}\\n\")\n",
    "    f.write(f\"ROUGE1 Scores: {rouge_scores['rouge1']}\\n\")\n",
    "    f.write(f\"ROUGE2 Scores: {rouge_scores['rouge2']}\\n\")\n",
    "    f.write(f\"ROUGEL Scores: {rouge_scores['rougeL']}\\n\")\n",
    "    f.write(f\"ROUGELsum Scores: {rouge_scores['rougeLsum']}\\n\")\n",
    "    f.write(f\"BERTScore (F1): {bert_score:.4f}\\n\")\n",
    "    f.write(f\"METEOR Score: {meteor_score:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c07a32-44b0-429a-9077-d873255a7f01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (super_art)",
   "language": "python",
   "name": "super_art"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
